{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrsergazinov/.conda/envs/tabllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import typing as ty\n",
    "import yaml\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import models and encoders\n",
    "os.chdir('/home/mrsergazinov/TabLLM/')\n",
    "from encoders.numEncoders import (\n",
    "    FourierFeatures, \n",
    "    BinningFeatures, \n",
    "    ComboFeatures,\n",
    "    SquareScalingFeatures,\n",
    ")\n",
    "\n",
    "from train_eval import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x = torch.relu(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def generate_dataset(n, p, M=10, kernel='gaussian', sigma=0.5):\n",
    "    # Generate nxp matrix of features\n",
    "    X = np.random.randn(n, p)\n",
    "    \n",
    "    # Generate points Z of dimension Mxp\n",
    "    Z = np.random.randn(M, p)\n",
    "    \n",
    "    # Generate alpha coefficients for each feature-point combination\n",
    "    alpha = np.random.randn(p, M)\n",
    "\n",
    "    # Define kernels\n",
    "    def gaussian_kernel(x, z, sigma=sigma):\n",
    "        # x and z are scalars here\n",
    "        return np.exp(-((x - z) ** 2) / sigma)\n",
    "\n",
    "    def hat_kernel(x, z, sigma=sigma):\n",
    "        return (np.abs(x - z) < sigma).astype(float)\n",
    "    \n",
    "    def laplace_kernel(x, z, sigma=sigma):\n",
    "        return np.exp(-np.abs(x - z) / sigma)\n",
    "    \n",
    "    # Choose kernel function based on input parameter\n",
    "    if kernel == 'gaussian':\n",
    "        k_func = gaussian_kernel\n",
    "    elif kernel == 'hat':\n",
    "        k_func = hat_kernel\n",
    "    elif kernel == 'laplace':\n",
    "        k_func = laplace_kernel\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kernel\")\n",
    "\n",
    "    # Compute y\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            # Compute kernel features for this dimension against all M points\n",
    "            k_values = [k_func(X[i, j], Z[m, j]) for m in range(M)]\n",
    "            y[i] += np.sum(alpha[j, :] * k_values)\n",
    "\n",
    "    # Add small Gaussian noise\n",
    "    y += np.random.randn(n) * 0.01\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n",
      "Raw features: 0.8932828307151794\n",
      "Fourier features with Normal: 0.12520308792591095\n",
      "Fourier features with Cauchy: 0.04882017523050308\n",
      "Seed: 1\n",
      "Raw features: 0.8054531216621399\n",
      "Fourier features with Normal: 6.725131034851074\n",
      "Fourier features with Cauchy: 4.577852725982666\n",
      "Seed: 2\n",
      "Raw features: 0.78705894947052\n",
      "Fourier features with Normal: 0.09973685443401337\n",
      "Fourier features with Cauchy: 0.07541023939847946\n",
      "Seed: 3\n",
      "Raw features: 0.789662778377533\n",
      "Fourier features with Normal: 0.04982997849583626\n",
      "Fourier features with Cauchy: 0.04209383577108383\n",
      "Seed: 4\n",
      "Raw features: 0.8271408677101135\n",
      "Fourier features with Normal: 0.13838732242584229\n",
      "Fourier features with Cauchy: 0.07183782756328583\n",
      "Seed: 5\n",
      "Raw features: 0.570482611656189\n",
      "Fourier features with Normal: 2.9672436714172363\n",
      "Fourier features with Cauchy: 0.604804277420044\n",
      "Seed: 6\n",
      "Raw features: 0.7397266626358032\n",
      "Fourier features with Normal: 0.030324863269925117\n",
      "Fourier features with Cauchy: 0.036668021231889725\n",
      "Seed: 7\n",
      "Raw features: 0.7505744695663452\n",
      "Fourier features with Normal: 0.03971509635448456\n",
      "Fourier features with Cauchy: 0.03964834287762642\n",
      "Seed: 8\n",
      "Raw features: 0.7404374480247498\n",
      "Fourier features with Normal: 0.5742919445037842\n",
      "Fourier features with Cauchy: 0.03665647283196449\n",
      "Seed: 9\n",
      "Raw features: 0.79896080493927\n",
      "Fourier features with Normal: 0.8576315641403198\n",
      "Fourier features with Cauchy: 3.7053298950195312\n",
      "Seed: 10\n",
      "Raw features: 0.7510562539100647\n",
      "Fourier features with Normal: 0.9606747627258301\n",
      "Fourier features with Cauchy: 0.08964614570140839\n",
      "Seed: 11\n",
      "Raw features: 0.6953110098838806\n",
      "Fourier features with Normal: 0.03805162012577057\n",
      "Fourier features with Cauchy: 0.029760969802737236\n",
      "Seed: 12\n",
      "Raw features: 0.7712197303771973\n",
      "Fourier features with Normal: 20.1618709564209\n",
      "Fourier features with Cauchy: 0.08120884746313095\n",
      "Seed: 13\n",
      "Raw features: 0.6641275882720947\n",
      "Fourier features with Normal: 0.03567357733845711\n",
      "Fourier features with Cauchy: 0.03291424736380577\n",
      "Seed: 14\n",
      "Raw features: 0.8084671497344971\n",
      "Fourier features with Normal: 0.015460633672773838\n",
      "Fourier features with Cauchy: 0.030013397336006165\n",
      "Seed: 15\n",
      "Raw features: 0.7090697288513184\n",
      "Fourier features with Normal: 0.027008624747395515\n",
      "Fourier features with Cauchy: 0.051362160593271255\n",
      "Seed: 16\n",
      "Raw features: 0.8248651027679443\n",
      "Fourier features with Normal: 0.030012881383299828\n",
      "Fourier features with Cauchy: 0.10813074558973312\n",
      "Seed: 17\n",
      "Raw features: 0.9785305857658386\n",
      "Fourier features with Normal: 66.4540023803711\n",
      "Fourier features with Cauchy: 0.2584249973297119\n",
      "Seed: 18\n",
      "Raw features: 0.7414252758026123\n",
      "Fourier features with Normal: 0.03171930089592934\n",
      "Fourier features with Cauchy: 0.031264420598745346\n",
      "Seed: 19\n",
      "Raw features: 0.7628150582313538\n",
      "Fourier features with Normal: 0.045957788825035095\n",
      "Fourier features with Cauchy: 0.04259436950087547\n",
      "Seed: 20\n",
      "Raw features: 0.6674367189407349\n",
      "Fourier features with Normal: 0.017097150906920433\n",
      "Fourier features with Cauchy: 0.021795155480504036\n",
      "Seed: 21\n",
      "Raw features: 0.6436069011688232\n",
      "Fourier features with Normal: 0.02601107396185398\n",
      "Fourier features with Cauchy: 0.03012882173061371\n",
      "Seed: 22\n",
      "Raw features: 0.7329731583595276\n",
      "Fourier features with Normal: 0.347624272108078\n",
      "Fourier features with Cauchy: 0.062483206391334534\n",
      "Seed: 23\n",
      "Raw features: 0.8807658553123474\n",
      "Fourier features with Normal: 1.9079349040985107\n",
      "Fourier features with Cauchy: 5.818928241729736\n",
      "Seed: 24\n",
      "Raw features: 0.714219331741333\n",
      "Fourier features with Normal: 27.5474796295166\n",
      "Fourier features with Cauchy: 2.844424247741699\n",
      "Seed: 25\n",
      "Raw features: 0.6893756985664368\n",
      "Fourier features with Normal: 0.01724362187087536\n",
      "Fourier features with Cauchy: 0.028042800724506378\n",
      "Seed: 26\n",
      "Raw features: 0.6821237802505493\n",
      "Fourier features with Normal: 98.2740707397461\n",
      "Fourier features with Cauchy: 11.93124008178711\n",
      "Seed: 27\n",
      "Raw features: 0.6274282336235046\n",
      "Fourier features with Normal: 0.5869879126548767\n",
      "Fourier features with Cauchy: 0.6150619983673096\n",
      "Seed: 28\n",
      "Raw features: 0.8126282691955566\n",
      "Fourier features with Normal: 0.09768366068601608\n",
      "Fourier features with Cauchy: 0.026170512661337852\n",
      "Seed: 29\n",
      "Raw features: 0.7921016812324524\n",
      "Fourier features with Normal: 505.0511169433594\n",
      "Fourier features with Cauchy: 210.3927001953125\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "for seed in range(30):\n",
    "    print(f\"Seed: {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    X, y = generate_dataset(10000, 10, kernel='laplace')\n",
    "    params = {\n",
    "        'model_name': 'MLP',\n",
    "        'num_encoder': 'NewFourierFeatures',\n",
    "        'num_encoder_trainable': False,\n",
    "        'scaler': 'SquareScalingFeatures',\n",
    "        'n_run': 1,\n",
    "        'config_file': 'configs/simulation.yaml',\n",
    "        'random_state': seed,\n",
    "        'test_size': 0.1,\n",
    "    }\n",
    "    task_type = 'regression'\n",
    "\n",
    "    # convet X to DataFrame and y to Series\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    # Pre-process the data: \n",
    "    # 1. standaridizes columns to mean=0 and std=1\n",
    "    # 2. standardizes target to mean=0 and std=1\n",
    "    # 3. splits the data into training, validation, and test sets\n",
    "    (y_train, \n",
    "     y_val, \n",
    "     y_test, \n",
    "     X_train_num, \n",
    "     X_val_num, \n",
    "     X_test_num, \n",
    "     X_train_cat, \n",
    "     X_val_cat, \n",
    "     X_test_cat) = preprocess_data(X, y, task_type, params)\n",
    "    y_test = y_test.numpy()\n",
    "\n",
    "    # Raw features -- linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_num, y_train)\n",
    "    y_pred = model.predict(X_test_num)\n",
    "    mse = np.mean((y_pred - y_test) ** 2)\n",
    "    results['Raw'].append(mse)\n",
    "    print(f\"Raw features: {mse}\")\n",
    "\n",
    "    # Fourier features with normal -- linear regression\n",
    "    # Encode the numerical features\n",
    "    encoder = FourierFeatures(\n",
    "       n_features=X_train_num.shape[1],\n",
    "       n_frequencies=10,\n",
    "       frequency_scale=0.5,\n",
    "       distribution='normal',\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        X_train_num_normal = encoder(X_train_num)\n",
    "        X_val_num_normal = encoder(X_val_num)\n",
    "        X_test_num_normal = encoder(X_test_num)\n",
    "    # Fit the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_num_normal, y_train)\n",
    "    y_pred = model.predict(X_test_num_normal)\n",
    "    # Compute the mean squared error\n",
    "    mse = np.mean((y_pred - y_test) ** 2)\n",
    "    results['Fourier_normal'].append(mse)\n",
    "    print(f\"Fourier features with Normal: {mse}\")\n",
    "\n",
    "\n",
    "    # Fourier features with cauchy -- linear regression\n",
    "    # Encode the numerical features\n",
    "    encoder = FourierFeatures(\n",
    "       n_features=X_train_num.shape[1],\n",
    "       n_frequencies=10,\n",
    "       frequency_scale=0.5,\n",
    "       distribution='cauchy',\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        X_train_num_cauchy = encoder(X_train_num)\n",
    "        X_val_num_cauchy = encoder(X_val_num)\n",
    "        X_test_num_cauchy = encoder(X_test_num)\n",
    "    # Fit the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_num_cauchy, y_train)\n",
    "    y_pred = model.predict(X_test_num_cauchy)\n",
    "    # Compute the mean squared error\n",
    "    mse = np.mean((y_pred - y_test) ** 2)\n",
    "    results['Fourier_cauchy'].append(mse)\n",
    "    print(f\"Fourier features with Cauchy: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 0.7508153915405273\n",
      "Fourier_normal: 0.11246997117996216\n",
      "Fourier_cauchy: 0.056922681629657745\n"
     ]
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    print(f\"{key}: {np.median(results[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
