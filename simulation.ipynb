{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import typing as ty\n",
    "import yaml\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Import models and encoders\n",
    "os.chdir('/home/mrsergazinov/TabLLM/')\n",
    "from base_models.mlp import MLP\n",
    "from base_models.tabTransformer import TabTransformer\n",
    "from base_models.modernNCA import ModernNCA\n",
    "from encoders.numEncoders import (\n",
    "    FourierFeatures, \n",
    "    BinningFeatures, \n",
    "    ComboFeatures,\n",
    "    SquareScalingFeatures,\n",
    ")\n",
    "\n",
    "from train_eval_adult import preprocess_data, train_and_evaluate_model\n",
    "\n",
    "MODELS = {\n",
    "    'MLP': MLP,\n",
    "    'TabTransformer': TabTransformer,\n",
    "    'ModernNCA': ModernNCA\n",
    "}\n",
    "\n",
    "ENCODERS = {\n",
    "    'FourierFeatures': FourierFeatures,\n",
    "    'BinningFeatures': BinningFeatures,\n",
    "    'ComboFeatures': ComboFeatures,\n",
    "}\n",
    "\n",
    "SCALERS = {\n",
    "    'SquareScalingFeatures': SquareScalingFeatures,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n, p):\n",
    "    # generate nxp matrix of features\n",
    "    X = np.random.randn(n, p)\n",
    "    \n",
    "    # Generate alpha coefficients\n",
    "    alpha = np.random.randn(p) * 0.1\n",
    "\n",
    "    # Define Gaussian kernel function\n",
    "    def gaussian_kernel(x1, x2, sigma=0.5):\n",
    "        return np.exp(-((x1 - x2) ** 2) / sigma)\n",
    "\n",
    "    # Compute logits\n",
    "    logits = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            kernel_sum = np.sum(gaussian_kernel(X[:, j], X[i, j]))\n",
    "            logits[i] += alpha[j] * kernel_sum\n",
    "\n",
    "    # Sample y from Bernoulli distribution with computed logits\n",
    "    probabilities = 1 / (1 + np.exp(-logits))\n",
    "    y = np.random.binomial(1, probabilities)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n",
      "Standard MLP: 91.05\n",
      "FourierFeatures + SquareScalingFeatures: 98.0\n",
      "FourierFeatures trainable: 97.4\n",
      "FourierFeatures: 96.7\n",
      "---------------\n",
      "Seed: 43\n",
      "Standard MLP: 100.0\n",
      "FourierFeatures + SquareScalingFeatures: 100.0\n",
      "FourierFeatures trainable: 100.0\n",
      "FourierFeatures: 100.0\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 44\n",
      "Standard MLP: 99.25\n",
      "FourierFeatures + SquareScalingFeatures: 99.5\n",
      "FourierFeatures trainable: 99.45\n",
      "FourierFeatures: 99.45\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 45\n",
      "Standard MLP: 90.3\n",
      "FourierFeatures + SquareScalingFeatures: 98.7\n",
      "FourierFeatures trainable: 97.6\n",
      "FourierFeatures: 97.55\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 46\n",
      "Standard MLP: 92.5\n",
      "FourierFeatures + SquareScalingFeatures: 98.7\n",
      "FourierFeatures trainable: 98.4\n",
      "FourierFeatures: 97.9\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 47\n",
      "Standard MLP: 90.7\n",
      "FourierFeatures + SquareScalingFeatures: 98.1\n",
      "FourierFeatures trainable: 97.95\n",
      "FourierFeatures: 98.1\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 48\n",
      "Standard MLP: 88.85\n",
      "FourierFeatures + SquareScalingFeatures: 98.4\n",
      "FourierFeatures trainable: 97.05\n",
      "FourierFeatures: 96.8\n",
      "---------------\n",
      "Seed: 49\n",
      "Standard MLP: 98.3\n",
      "FourierFeatures + SquareScalingFeatures: 99.3\n",
      "FourierFeatures trainable: 98.9\n",
      "FourierFeatures: 98.9\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 50\n",
      "Standard MLP: 89.25\n",
      "FourierFeatures + SquareScalingFeatures: 97.4\n",
      "FourierFeatures trainable: 97.55\n",
      "FourierFeatures: 96.95\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.573377/ipykernel_419651/3911946877.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probabilities = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 51\n",
      "Standard MLP: 99.05\n",
      "FourierFeatures + SquareScalingFeatures: 99.35\n",
      "FourierFeatures trainable: 99.3\n",
      "FourierFeatures: 99.15\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEEDS = [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]\n",
    "\n",
    "results = defaultdict(list)\n",
    "for seed in SEEDS:\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    X, y = generate_dataset(10000, 10)\n",
    "    params = {\n",
    "        'model_name': 'MLP',\n",
    "        'num_encoder': None,\n",
    "        'num_encoder_trainable': False,\n",
    "        'scaler': None,\n",
    "        'n_run': 1,\n",
    "        'config_file': 'configs/simulation.yaml',\n",
    "        'random_state': seed,\n",
    "        'test_size': 0.2,\n",
    "    }\n",
    "    task_type = 'binary_classification'\n",
    "\n",
    "    # convet X to DataFrame and y to Series\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    print(f\"Seed: {seed}\")\n",
    "\n",
    "    y_train, y_test, X_train_num, X_train_cat, X_test_num, X_test_cat = preprocess_data(X, y, task_type, params)\n",
    "    metric = train_and_evaluate_model(\n",
    "        X_train_num=X_train_num,\n",
    "        X_test_num=X_test_num,\n",
    "        X_train_cat=X_train_cat,\n",
    "        X_test_cat=X_test_cat,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        task_type=task_type,\n",
    "        params=params,\n",
    "        verbose_training=False,\n",
    "        verbose_evaluation=False,\n",
    "    )\n",
    "    print(f\"Standard MLP: {metric}\")\n",
    "    results['Standard MLP'].append(metric)\n",
    "\n",
    "    params['num_encoder'] = 'FourierFeatures'\n",
    "    params['scaler'] = 'SquareScalingFeatures'\n",
    "    metric = train_and_evaluate_model(\n",
    "        X_train_num=X_train_num,\n",
    "        X_test_num=X_test_num,\n",
    "        X_train_cat=X_train_cat,\n",
    "        X_test_cat=X_test_cat,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        task_type=task_type,\n",
    "        params=params,\n",
    "        verbose_training=False,\n",
    "        verbose_evaluation=False,\n",
    "    )\n",
    "    print(f\"FourierFeatures + SquareScalingFeatures: {metric}\")\n",
    "    results['FourierFeatures + SquareScalingFeatures'].append(metric)\n",
    "\n",
    "    params['num_encoder'] = 'FourierFeatures'\n",
    "    params['num_encoder_trainable'] = True\n",
    "    params['scaler'] = None\n",
    "    metric = train_and_evaluate_model(\n",
    "        X_train_num=X_train_num,\n",
    "        X_test_num=X_test_num,\n",
    "        X_train_cat=X_train_cat,\n",
    "        X_test_cat=X_test_cat,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        task_type=task_type,\n",
    "        params=params,\n",
    "        verbose_training=False,\n",
    "        verbose_evaluation=False,\n",
    "    )\n",
    "    print(f\"FourierFeatures trainable: {metric}\")\n",
    "    results['FourierFeatures_trainable'].append(metric)\n",
    "\n",
    "\n",
    "    params['num_encoder'] = 'FourierFeatures'\n",
    "    params['num_encoder_trainable'] = False\n",
    "    params['scaler'] = None\n",
    "    metric = train_and_evaluate_model(\n",
    "        X_train_num=X_train_num,\n",
    "        X_test_num=X_test_num,\n",
    "        X_train_cat=X_train_cat,\n",
    "        X_test_cat=X_test_cat,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        task_type=task_type,\n",
    "        params=params,\n",
    "        verbose_training=False,\n",
    "        verbose_evaluation=False,\n",
    "    )\n",
    "    print(f\"FourierFeatures: {metric}\")\n",
    "    results['FourierFeatures'].append(metric)\n",
    "    print('-'*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
