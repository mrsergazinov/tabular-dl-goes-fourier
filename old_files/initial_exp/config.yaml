# config.yaml

dataset:
  name: "adult"
  version: 2
  test_size: 0.2
  random_state: 42
  batch_size: 32

tabtransformer:
  input_dim: null  # Will be set dynamically based on the dataset
  output_dim: 256
  num_heads: 8
  num_layers: 6

llama:
  use_llama: true
  model_name: "meta-llama/Meta-Llama-3-8B"
  start_layer: 0   # Start index of LLaMA layers to use
  end_layer: 34     # End index (exclusive) of LLaMA layers to use

training:
  criterion: 'cross_entropy'
  learning_rate: 0.00001
  epochs: 10

# 86.61%
# 86.54%
# 86.43%
# 86.09

# torchrun --nproc_per_node=8 train.py