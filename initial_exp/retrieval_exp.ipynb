{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "os.chdir('/home/mrsergazinov/TabLLM/initial_exp/')\n",
    "from retrieval_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset to keep track of indices\n",
    "class IndexedTensorDataset(Dataset):\n",
    "    def __init__(self, tensors_num, tensors_cat, targets):\n",
    "        self.tensors_num = tensors_num\n",
    "        self.tensors_cat = tensors_cat\n",
    "        self.targets = targets\n",
    "        self.indices = torch.arange(len(tensors_num), dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.tensors_num[index], self.tensors_cat[index], self.targets[index], self.indices[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensors_num)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def label_encode(X, categorical_columns):\n",
    "    le_categorical = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        le_categorical[col] = le  # Save each encoder if needed for inverse transformation later\n",
    "    return X, le_categorical\n",
    "\n",
    "def llm_encoder(X, categorical_columns, batch_size=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Step 1: Prepare text embeddings\n",
    "    embeddings = []\n",
    "    for idx in range(X.shape[0]):\n",
    "        string = ''\n",
    "        for column in categorical_columns:\n",
    "            string += f\"{column}: {X[column][idx]}. \"\n",
    "        embeddings.append(string)\n",
    "\n",
    "    # Load tokenizer and model, move model to device\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2').to(device)\n",
    "\n",
    "    # Step 2: Process embeddings in batches\n",
    "    batch_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(embeddings), batch_size):\n",
    "            batch_texts = embeddings[i:i+batch_size]\n",
    "            encoded_input = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "            model_output = model(**encoded_input)\n",
    "            batch_embeddings.append(mean_pooling(model_output, encoded_input['attention_mask']).cpu())\n",
    "            print(f'Processed {i+batch_size}/{len(embeddings)} embeddings')\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "    embeddings_df = pd.DataFrame(embeddings_tensor.numpy(), columns=[f'embedding_{i}' for i in range(embeddings_tensor.shape[1])])\n",
    "\n",
    "    # Clean up memory\n",
    "    del encoded_input, model_output, batch_embeddings, embeddings_tensor, tokenizer, model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Step 3: Concatenate embeddings with the original DataFrame and drop categorical columns\n",
    "    X = pd.concat([X.reset_index(drop=True), embeddings_df], axis=1)\n",
    "    X = X.drop(columns=categorical_columns)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def onehot_encode(X, categorical_columns):\n",
    "    X = pd.get_dummies(X, columns=categorical_columns, drop_first = True)\n",
    "    return X\n",
    "\n",
    "def load_dataset(config):\n",
    "    # Fetch the dataset\n",
    "    data = fetch_openml(config['dataset']['name'], version=config['dataset']['version'], as_frame=True)\n",
    "    X = data['data'].copy()\n",
    "    y = data['target']\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_columns = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "    numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    if config['dataset']['cat_encode'] == 'label':\n",
    "        X, _ = label_encode(X, categorical_columns)\n",
    "    elif config['dataset']['cat_encode'] == 'onehot':\n",
    "        X = onehot_encode(X, categorical_columns)\n",
    "    elif config['dataset']['cat_encode'] == 'llm':\n",
    "        X = llm_encoder(X, categorical_columns)\n",
    "    \n",
    "    # Scale numerical columns\n",
    "    numerical_transformer = StandardScaler()\n",
    "    X[numerical_columns] = numerical_transformer.fit_transform(X[numerical_columns])\n",
    "\n",
    "    # Encode the target variable\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(y)\n",
    "\n",
    "    # Convert X and y to tensor\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    if config['dataset']['all_num']:\n",
    "        X_num = torch.tensor(X.values, dtype=torch.float32)\n",
    "        X_cat = X_num.clone()\n",
    "        d_in_num = X_num.shape[1]\n",
    "        d_in_cat = 0\n",
    "    else:\n",
    "        X_num = torch.tensor(X[numerical_columns].values, dtype=torch.float32)\n",
    "        X_cat = torch.tensor(X.drop(columns=numerical_columns).values, dtype=torch.float32)\n",
    "        d_in_num = X_num.shape[1]\n",
    "        d_in_cat = X_cat.shape[1]\n",
    "\n",
    "    return (X_num, X_cat, y, d_in_num, d_in_cat, le_target)\n",
    "\n",
    "\n",
    "def evaluate(config, model, test_loader, criterion, device, X_num_train, X_cat_train, y_train):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_num_batch, X_cat_batch, y_batch, idx_batch in test_loader:\n",
    "            X_num_batch = X_num_batch.to(device)\n",
    "            X_cat_batch = X_cat_batch.to(device) if not config['dataset']['all_num'] else None\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Use entire training data as candidates during evaluation\n",
    "            candidate_x_num = X_num_train.to(device) \n",
    "            candidate_x_cat = X_cat_train.to(device) if not config['dataset']['all_num'] else None\n",
    "            candidate_y = y_train.to(device)\n",
    "\n",
    "            # Forward pass with separate categorical and numerical features\n",
    "            logits = model(\n",
    "                x_num=X_num_batch,\n",
    "                x_cat=X_cat_batch,\n",
    "                y=None,\n",
    "                candidate_x_num=candidate_x_num,\n",
    "                candidate_x_cat=candidate_x_cat,\n",
    "                candidate_y=candidate_y\n",
    "            )\n",
    "\n",
    "            # Convert logits to predictions\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits, y_batch)\n",
    "            test_loss += loss.item() * y_batch.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    test_loss = test_loss / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f} | Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "def train(config):\n",
    "    set_seed(config['dataset']['random_state'])\n",
    "\n",
    "    X_num, X_cat, y, d_in_num, d_in_cat, le_target = load_dataset(config)\n",
    "    print(X_num)\n",
    "    output_classes = len(le_target.classes_)\n",
    "\n",
    "    X_num_train, X_num_test, X_cat_train, X_cat_test, y_train, y_test = train_test_split(\n",
    "        X_num, X_cat, y, test_size=config['dataset']['test_size'], random_state=config['dataset']['random_state']\n",
    "    )\n",
    "\n",
    "    # Use IndexedTensorDataset for separate numerical and categorical data\n",
    "    train_dataset = IndexedTensorDataset(X_num_train, X_cat_train, y_train)\n",
    "    test_dataset = IndexedTensorDataset(X_num_test, X_cat_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True,\n",
    "        pin_memory=True, num_workers=4\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False,\n",
    "        pin_memory=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the ModernNCA model\n",
    "    model = KernelNCA(\n",
    "        d_in_num=d_in_num,\n",
    "        d_in_cat=d_in_cat,\n",
    "        d_out=output_classes,\n",
    "        dim=config['model']['dim'],\n",
    "        dropout=config['model']['dropout'],\n",
    "        n_frequencies=config['model']['n_frequencies'],\n",
    "        frequency_scale=config['model']['frequency_scale'],\n",
    "        d_embedding=config['model']['d_embedding'],\n",
    "        lite=config['model']['lite'],\n",
    "        temperature=config['model']['temperature'],\n",
    "        use_llama=config['model']['use_llama'],\n",
    "        llama_model_name=config['model']['llama_model_name'],\n",
    "        start_layer=config['model']['start_layer'],\n",
    "        end_layer=config['model']['end_layer']\n",
    "    )\n",
    "    model = model.float()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    print(model.delta)\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.Adam(\n",
    "    #     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    #     lr=config['training']['learning_rate'],\n",
    "    #     weight_decay=config['training']['weight_decay']\n",
    "    # )\n",
    "\n",
    "    # # Training loop\n",
    "    # for epoch in range(config['training']['epochs']):\n",
    "    #     model.train()\n",
    "    #     start_time = time.time()\n",
    "    #     epoch_loss = 0.0\n",
    "    #     correct = 0\n",
    "    #     total = 0\n",
    "\n",
    "    #     for itr, (X_num_batch, X_cat_batch, y_batch, idx_batch) in enumerate(train_loader):\n",
    "    #         X_num_batch = X_num_batch.to(device)\n",
    "    #         X_cat_batch = X_cat_batch.to(device) if not config['dataset']['all_num'] else None\n",
    "    #         y_batch = y_batch.to(device)\n",
    "\n",
    "    #         # Exclude current batch for candidates\n",
    "    #         mask = ~torch.isin(torch.arange(X_num_train.shape[0]), idx_batch)\n",
    "    #         true_indices = torch.arange(X_num_train.shape[0])[mask]\n",
    "    #         num_samples = int(len(true_indices) * config['model']['sample_rate'])\n",
    "    #         sampled_indices = true_indices[torch.randperm(len(true_indices))[:num_samples]]\n",
    "    #         sampled_mask = torch.zeros_like(mask, dtype=torch.bool)\n",
    "    #         sampled_mask[sampled_indices] = True\n",
    "\n",
    "    #         # Use the new sampled_mask to filter out elements\n",
    "    #         candidate_x_num = X_num_train[sampled_mask].to(device)\n",
    "    #         candidate_x_cat = X_cat_train[sampled_mask].to(device) if not config['dataset']['all_num'] else None\n",
    "    #         candidate_y = y_train[sampled_mask].to(device)\n",
    "\n",
    "    #         optimizer.zero_grad()\n",
    "    #         # Forward pass with separate categorical and numerical features\n",
    "    #         logits = model(\n",
    "    #             x_num=X_num_batch,\n",
    "    #             x_cat=X_cat_batch,\n",
    "    #             y=y_batch,\n",
    "    #             candidate_x_num=candidate_x_num,\n",
    "    #             candidate_x_cat=candidate_x_cat,\n",
    "    #             candidate_y=candidate_y\n",
    "    #         )\n",
    "    #         loss = criterion(logits, y_batch)\n",
    "\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "    #         epoch_loss += loss.item() * y_batch.size(0)\n",
    "    #         _, predicted = torch.max(logits, 1)\n",
    "    #         total += y_batch.size(0)\n",
    "    #         correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    #         if itr % 50 == 0:\n",
    "    #             print(f'Iteration [{itr}/{len(train_loader)}] | Loss: {loss.item():.4f} | '\n",
    "    #                     f'Accuracy: {100 * correct / total:.2f}%')\n",
    "                \n",
    "\n",
    "    #     epoch_loss = epoch_loss / total\n",
    "    #     epoch_acc = 100 * correct / total\n",
    "    #     epoch_time = time.time() - start_time\n",
    "\n",
    "    #     print(f'Epoch [{epoch+1}/{config[\"training\"][\"epochs\"]}] | Loss: {epoch_loss:.4f} | '\n",
    "    #             f'Accuracy: {epoch_acc:.2f}% | Time: {epoch_time:.2f}s')\n",
    "\n",
    "    evaluate(config, model, test_loader, criterion, device, X_num_train, X_cat_train, y_train)\n",
    "\n",
    "    # save the model\n",
    "    path = config['training']['model_path']\n",
    "    torch.save(model.state_dict(), path)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    evaluate(config, model, test_loader, criterion, device, X_num_train, X_cat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('retrieval_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9951,  0.3517, -1.1973, -0.1448, -0.2171, -0.0341],\n",
      "        [-0.0469, -0.9455, -0.4193, -0.1448, -0.2171,  0.7729],\n",
      "        [-0.7763,  1.3947,  0.7476, -0.1448, -0.2171, -0.0341],\n",
      "        ...,\n",
      "        [ 1.4118, -0.3575, -0.4193, -0.1448, -0.2171, -0.0341],\n",
      "        [-1.2139,  0.1120, -0.4193, -0.1448, -0.2171, -1.6481],\n",
      "        [ 0.9742,  0.9305, -0.4193,  1.8713, -0.2171, -0.0341]])\n",
      "Parameter containing:\n",
      "tensor([[52.9362, 54.9002, 22.9718, 57.5583, 23.4269, 36.0537, 15.3943, 47.6185,\n",
      "         56.4463,  7.9912, 56.0759, 35.6148, 52.1643, 34.0629, 44.4656, 25.7643,\n",
      "         53.1266, 34.4343, 15.9948, 37.6469, 16.1779, 26.4818, 17.8153, 49.9011,\n",
      "          6.3189, 16.1697, 21.5288, 11.9618, 32.8315,  0.3696, 57.0933,  4.5160,\n",
      "         53.1608, 34.9926, 20.2589, 48.5385, 34.6755, 54.2389, 33.2796, 20.5388,\n",
      "         38.0605, 21.8646, 42.6257, 56.7847, 47.3418, 16.8848, 47.3179, 35.3678,\n",
      "         45.2351, 11.7148,  0.3027, 18.4092,  6.9893, 54.6162, 38.6409, 42.4264,\n",
      "         39.4878, 29.4781, 53.4782,  8.6846, 31.8889,  9.5238, 39.2506, 19.6685,\n",
      "         39.1925, 23.7498, 54.8818, 12.2189, 12.1081, 12.1070, 56.9833, 39.9975,\n",
      "         58.8675,  5.2417,  0.2437,  6.5291,  9.8193, 42.1512, 40.7423, 54.9277,\n",
      "         14.5072,  9.5486, 45.9173, 17.8739, 48.2077, 22.8810, 47.1614,  6.6910,\n",
      "         14.8605, 39.1463, 36.3422, 22.3512, 47.8821, 50.3943,  8.2448, 13.9840,\n",
      "         57.4699, 19.8770, 19.3645,  0.9722],\n",
      "        [12.8199, 37.4941, 26.0402,  8.2234, 30.7037,  9.5076,  4.5481, 13.4801,\n",
      "          3.7436, 10.8979, 59.9883, 35.6662, 39.2448,  2.0195, 10.2968, 20.0143,\n",
      "         34.6911,  3.6024, 17.0738, 12.0399, 30.0831, 18.8369, 27.9211,  9.6711,\n",
      "          9.4081, 12.4979, 19.7311,  6.3216, 55.1541, 24.0461, 55.8119, 39.3475,\n",
      "          4.5961, 50.7611, 21.7457, 18.5002,  5.0979,  0.1752, 38.5833, 23.4467,\n",
      "         41.6797,  5.3801, 52.2729,  7.9784, 24.8198, 36.2661, 45.4876, 54.2193,\n",
      "         57.3288,  6.2123, 37.5500, 17.0962, 26.7125,  7.5453, 57.3258,  7.9815,\n",
      "         46.0335, 40.5432, 39.7487, 13.7806, 57.2685, 36.5925, 33.8592,  3.5624,\n",
      "         42.5937, 25.4994, 16.2563, 55.7684, 36.6885, 13.4017, 14.8158, 28.5673,\n",
      "         46.7508, 22.3340, 12.8828, 19.7267,  7.5878, 40.6990, 53.2212,  1.7568,\n",
      "         36.9675, 45.4978, 35.4399, 19.3163, 45.6583, 45.7654, 41.2178, 24.7284,\n",
      "         22.0560, 33.2094, 24.7004, 21.0600, 49.1762, 55.7820, 27.0301, 23.2831,\n",
      "         30.4378, 28.2088, 37.2123, 38.4070],\n",
      "        [ 2.7523, 18.9289, 55.2639, 41.6866, 28.5079, 11.9128, 11.6458,  3.1270,\n",
      "         20.2211, 40.1311, 49.1287, 43.8509,  3.4817, 11.9591, 25.2655, 59.0205,\n",
      "         34.3397, 22.2309, 42.4115, 18.5736, 10.5823, 51.8966, 16.3589, 23.9860,\n",
      "          0.1559, 50.0781, 52.7290, 40.9334,  9.0818,  0.3918,  5.6346, 52.3710,\n",
      "         44.4032, 55.2451, 45.7161, 37.5928, 29.7062,  7.1848,  4.2968,  1.9395,\n",
      "         42.2809, 15.2710, 23.9624, 12.7348, 24.5333,  8.8850, 10.3975, 39.9513,\n",
      "         21.0841, 48.5203, 20.3757,  7.9930, 24.7068, 15.4576, 20.8218,  1.4401,\n",
      "         46.7847,  9.1139, 45.0785, 43.6135, 51.4330,  6.9884, 51.5759, 15.8175,\n",
      "         41.1321, 58.1734, 25.7690, 29.7680, 23.0931,  4.9505, 44.3971,  0.2185,\n",
      "         48.6240, 52.4468, 58.3712, 22.9236,  5.3507, 36.7449, 46.5728,  0.1407,\n",
      "         23.1905, 12.0163, 27.3761, 15.2336, 17.7370, 20.4762,  1.4909, 54.6152,\n",
      "         55.1499, 25.2939, 26.5835, 17.7564,  2.9081,  0.8057, 41.1498, 13.5286,\n",
      "         10.7137, 27.6593, 20.0097, 20.2944],\n",
      "        [30.9639, 23.6366, 19.6706, 15.6358,  5.5852, 55.1552, 17.9944, 37.9494,\n",
      "         19.5910, 32.4378, 57.9690, 43.8217,  4.0020, 41.9071, 58.4773, 37.8925,\n",
      "         50.1127, 59.5766, 25.4031, 36.2266,  9.1489, 23.8177, 52.2175, 45.3794,\n",
      "         11.0163,  5.9434,  9.4991,  0.3937,  6.8508, 22.5811, 50.2463, 35.0215,\n",
      "          7.1818,  5.9333, 44.9243,  7.6848, 26.3062, 44.3912, 16.1156, 26.7288,\n",
      "         27.3887, 22.9025, 14.7890,  3.2568,  5.7493, 13.9361, 58.9751, 15.5096,\n",
      "          9.8542, 37.2718, 38.2683, 46.4373, 52.8036, 46.7062,  0.2550, 32.6607,\n",
      "         48.1726, 27.2272, 12.3216, 58.6002, 18.7792, 12.9197,  2.9533, 31.3400,\n",
      "         43.2940, 36.6409, 35.9325,  7.2484,  1.9834, 30.5283, 57.3550, 47.3076,\n",
      "         12.5330, 26.1057,  7.8845, 15.5273, 35.4329, 46.3362, 54.8511,  2.4568,\n",
      "         50.0585,  8.8412, 41.2340, 55.3874, 30.4213, 57.2943,  4.4385, 18.5412,\n",
      "         47.4976, 23.4640, 23.8590, 17.4963, 50.6792, 44.7151, 39.6135, 13.1411,\n",
      "          5.6475, 33.2448, 38.8884, 16.1486],\n",
      "        [21.6061, 50.2610, 32.3898, 31.3535, 22.6170,  2.8323,  1.7923, 15.6595,\n",
      "         14.7504, 39.3466, 21.2667, 18.2633, 58.6029, 40.4497, 51.3871, 15.4766,\n",
      "         17.7460, 41.0262, 10.0117, 10.3889, 28.5510, 19.0272,  7.5103, 47.7948,\n",
      "         54.1249, 34.8667, 24.7766,  2.2118, 19.0728, 37.6376, 44.1459, 26.2075,\n",
      "         18.1394, 46.7168,  6.1080, 48.9605, 18.3614, 30.4592, 24.0715, 33.6372,\n",
      "         20.9340, 51.8138, 29.2201, 53.4180, 58.8444, 15.3843,  8.1147, 54.0691,\n",
      "         53.5084,  7.0936, 27.6809,  0.4162,  5.4420, 35.7943, 37.9810, 36.3594,\n",
      "         21.8351, 57.6773, 34.2893, 12.2975, 28.3016, 37.2044, 40.5058,  8.7876,\n",
      "         41.2437, 14.6735,  5.0718, 13.6138, 58.9323, 55.6457, 56.8645, 47.6103,\n",
      "         52.6635, 25.9845, 13.4932, 44.9897, 14.4545,  9.7540, 20.4200, 36.2958,\n",
      "         45.4439, 18.3477, 12.3430, 34.0468, 12.3170, 10.4682, 45.6376, 24.9605,\n",
      "         57.4136, 59.1835, 38.9732, 40.3247, 36.9085, 30.4698, 27.8180, 30.4123,\n",
      "         41.2027, 57.8931, 22.2252, 17.3185],\n",
      "        [22.7351, 15.5063, 35.1012, 52.3935, 53.4593, 43.7738,  7.9221, 13.8989,\n",
      "         23.4087, 24.4703, 32.4674,  2.4609, 39.3373,  7.1138, 11.0177,  5.0585,\n",
      "         56.1396,  1.5918, 52.6310, 28.9915, 26.5110, 48.7644, 27.2272, 48.8146,\n",
      "         51.6904,  3.9537, 41.5435, 35.6634, 36.4504, 34.3797, 38.2059, 15.5680,\n",
      "         26.1618, 58.5036, 50.1555, 28.8729,  1.7841, 31.3148,  9.5708, 54.3957,\n",
      "         11.7874, 27.8340, 23.3417, 35.3386, 58.2308, 32.8506, 47.3749, 53.2866,\n",
      "         54.2193, 19.6395, 23.2903, 44.4581, 21.8140, 44.0479, 23.4460,  9.6524,\n",
      "         42.2113, 34.5995, 43.3755, 59.8046, 50.4820, 58.4394, 31.6057,  4.1936,\n",
      "          8.9542, 11.3648,  3.5625, 14.9626,  2.3830,  2.3215, 12.0734,  0.4250,\n",
      "         11.5856, 41.4393, 55.0216, 21.0761, 21.2736, 46.0186, 15.1989, 15.8150,\n",
      "         48.4839,  3.8610, 33.6682, 56.5015, 35.1446, 38.1583, 12.5283, 29.5861,\n",
      "         31.6495, 37.3630, 41.6564, 56.0678,  7.1010, 30.8993, 15.0109,  6.2681,\n",
      "         27.5977,  3.5929, 50.9370, 33.4744]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Test Loss: 0.3309 | Test Accuracy: 84.86%\n",
      "Test Loss: 0.3309 | Test Accuracy: 84.86%\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
