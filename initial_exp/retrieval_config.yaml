dataset:
  name: "adult"
  version: 2
  test_size: 0.2
  random_state: 42
  batch_size: 32

model:
  dim: 128
  dropout: 0.1
  n_frequencies: 77
  frequency_scale: 0.04431360576139521
  d_embedding: 34
  lite: true
  temperature: 1.0
  sample_rate: 0.1
  use_llama: True
  llama_model_name: "meta-llama/Meta-Llama-3-8B" # "meta-llama/Llama-3.2-1B"
  start_layer: 0
  end_layer: 8

training:
  learning_rate: 0.001
  weight_decay: 0.0002
  epochs: 10

# without: 86.96
# llama 3.2 1B
#   layers 0-1: 86.52
#   removed top projection: 
#     layers 0-1: 86.61
#     layers 0-8: 86.74
# mixed precision:
#    llama 3 8B
#       removed top projection:
#          layers 0-8: 86.85