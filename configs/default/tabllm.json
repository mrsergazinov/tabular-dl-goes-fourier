{
    "tabllm": {
        "model": {
            "base_model": {
                "token_bias": true,
                "n_layers": 3,
                "d_token": 192,
                "n_heads": 8,
                "d_ffn_factor": 1.3333333333333333,
                "attention_dropout": 0.2,
                "ffn_dropout": 0.1,
                "residual_dropout": 0.0,
                "activation": "reglu",
                "prenormalization": false,
                "initialization": "kaiming",
                "kv_compression": null,
                "kv_compression_sharing": null
            },
            "llm_model": {
                "llm_model_name": "meta-llama/Llama-3.2-3B",
                "base_output_dim": 192,
                "start_layer": 0,
                "end_layer": 10
            }
        },
        "training": {
            "lr": 0.0001,
            "weight_decay": 1e-05,
            "batch_size": 16
        },
        "general": {}
    }
}